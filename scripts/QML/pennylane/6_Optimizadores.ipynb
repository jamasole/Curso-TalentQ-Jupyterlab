{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe5a129",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://quantumspain-project.es/wp-content/uploads/2022/11/Logo_QS_EspanaDigital.png\" width=\"1000px\"/><br><br><br><br>\n",
    "\n",
    "\n",
    "# QML (Quantum Machine Learning)\n",
    "\n",
    "Created: 2022/10/30\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img aling=\"left\" alt=\"Licencia Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />License: <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional</a>.\n",
    "Internal Reviewers:\n",
    "* Alba Cervera ([BSC](https://www.bsc.es/))\n",
    "\n",
    "Authors:\n",
    "* Carmen Calvo ([SCAYLE](https://www.scayle.es/))\n",
    "* Antoni Alou ([PIC](https://www.pic.es/))\n",
    "* Carlos Hernani ([UV](https://www.uv.es/))\n",
    "* Nahia Iriarte ([NASERTIC](https://www.nasertic.es/es))\n",
    "* Carlos Luque ([IAC](https://www.iac.es/))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abddd41",
   "metadata": {},
   "source": [
    "# 6. Optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a6bed",
   "metadata": {},
   "source": [
    "## 6.1. Definiciones necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866fffc",
   "metadata": {},
   "source": [
    "**Función convexa**:Una función es convexa en un punto cuando la función cae por encima de la tangente en ese punto.(http://cimanet.uoc.edu/cursMates0/IniciacionMatematicas/s11/2_6_8.html) En otras palabras, consideramos que una función es convexa cuando tiene forma de valle, una función de este tipo se visualiza como en la imagen 1.\n",
    "\n",
    "<img src=\"imagenes/Convexa_funcion.png\" width=\"200\"/>\n",
    "<center>Imagen 1. Visualización función convexa.</center>\n",
    "\n",
    "\n",
    "**Función concava**: Una función es cóncava en un punto cuando la función cae por debajo de la tangente en ese punto. (http://cimanet.uoc.edu/cursMates0/IniciacionMatematicas/s11/2_6_8.html) Dicho de otra manera, este tipo de funciones se asemejan a la forma de una montaña, tal y como se muestra en la imagen 2.\n",
    "\n",
    "<img src=\"imagenes/Concava_funcion.png\" width=\"200\"/>\n",
    "<center>Imagen 2. Visualización función cóncava.</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f91e08",
   "metadata": {},
   "source": [
    "## 6.2. Métodos de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec21180",
   "metadata": {},
   "source": [
    "En el notebook de [introducción](1_Introduction.ipynb) el aprendizaje automático trata de construir algoritmos que puedan aprender de las observaciones existentes y aprovechar ese aprendizaje para predecir nuevas observaciones o determinar el resultado de nuevas entradas. Para esto, se requiere de un proceso iterativo en el que se busca minimizar el error realizando dicha tarea, lo que se conoce como entrenar el modelo. (https://planetachatbot.com/conceptos-fundamentales-en-machine-learning-funcon-de-perdida-y-optimizacion/)\n",
    "\n",
    "A la hora de llevar a cabo el entrenamiento del algoritmo es importante evaluar la calidad del modelo, de manera que se conozca la precisión o corrección del modelo. Para ello es necesario definir el concepto función de coste, que se encargará de medir el la calidad del algoritmo. \n",
    "\n",
    "Se denomina **función de coste** a aquella función que representa la calidad de la solución al problema planteado. Por lo tanto, para poder evaluar como de buena es una solución, esta debe recoger información asociada al problema mediante una expresión matemática de manera que penalice las peores soluciones y favorezca aquellas que proporcionen buenos resultados.\n",
    "\n",
    "El objetivo del entremaniento de un modelo es obtener la mayor precisión posible o lo que es lo mismo el menor error posible, es decir, se procede a minimizar la función de coste asociada a dicho algoritmo. La tarea de minimizar este tipo de funciones no es sencilla y existen diversas técnicas para abordarla, algunas de ellas se encuentran a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383cc1d",
   "metadata": {},
   "source": [
    "### 6.2.1. Descenso por gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30524e7",
   "metadata": {},
   "source": [
    "El descenso por gradiente (*gradient descent*) es un algoritmo de optimización utilizado para llevar a cabo el entrenamiento de modelos de *Machine Learning* y *Deep learning* mediante la minimización del error comentido (https://www.ibm.com/mx-es/topics/gradient-descent). Para llevar a cabo su proposito, está técnica hace uso del gradiente de la función a minimizar.\n",
    "\n",
    "Tal y como su nombre indica, este algoritmo se basa en el concepto de gradiente, a continuación se adjunta una breve explicación de este concepto para asentar los términos necesarios para entender el algoritmo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c698d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\",text-align:center>\n",
    "\n",
    "<details>\n",
    "<summary><p style=\"text-align:left\"> >>Gradiente </p></summary>\n",
    "\n",
    "En matemáticas el **gradiente** es una generalización de la derivada. La derivada se puede definir solo en funciones de una sola variable, en funciones de varias variables este término se denomina gradiente. Debido a esto, el gradiente es una función de valor vectorial a diferencia de una derivada que toma un valor escalar.\n",
    "\n",
    "Al igual que la derivada, el gradiente representa la pendiente de la recta tangente a la función estudiada, concretamente el gradiente apunta a aquellos puntos de la función con mayor incremento. \n",
    "  \n",
    "\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfcd084",
   "metadata": {},
   "source": [
    "El método de descenso por gradiente halla el minimo de una función, para ello asume que se puede obtener el gradiente de la función a estudiar y que esta es contínua y diferenciable (no necesariamente en toda la función)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce41afd",
   "metadata": {},
   "source": [
    "#### 6.2.1.1. Idea intuitiva del algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268b4f2",
   "metadata": {},
   "source": [
    "A continuación, con la finalidad de entender la filosofía que sigue este algoritmo, se adjunta la idea intuitiva en la que se basa esta técnica. Imagina que te encuentras en una montaña y tu objetivo es llegar al pueblo que se encuentra en sus faldas, pero tienes visión limitada. Es decir, deseas bajar pero no puedes ver el camino de bajada ya que únicamente puedes observar la pendiente a tu alrededor. La intuición nos dice que tras observar alrededor deberíamos avanzar en aquella dirección con mayor pendiente negativa, es decir, en la dirección con descenso más rápido. Repitiendo este proceso de manera iterativa probablemente lleguemos a nuestro destino final.\n",
    "\n",
    "El algoritmo de descenso por gradiente sigue esta misma filosofia, avanzar en la dirección de mayor descenso. Una vez se conoce la idea entorno a la que se diseña el algoritmo, seremos capaces de entender la explicación más técnica del siguiente apartado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0b591",
   "metadata": {},
   "source": [
    "#### 6.2.1.2. Algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8001a97",
   "metadata": {},
   "source": [
    "Tal y como se comentaba anteriormente, el descenso por gradiente (*gradient descent*) es un algoritmo de optimización iterativo utilizado para entrenar modelos de *Machine Learning*, el objetivo que persigue está estrategía es minimizar la función de error. \n",
    "\n",
    "Para poder implementar este algoritmo de optimización se debe definir la dirección y la **tasa de aprendizaje** (también conocido como el tamaño del paso). El primero de ellos nos indica en qué dirección seguir explorando el conjunto de soluciones mientras que el segundo especifica cuanto avanzar en la dirección seleccionada (https://github.com/vlarobbyk/descenso-por-gradiente/blob/master/GradientDescent-1.ipynb). \n",
    "\n",
    "El algoritmo parte desde un punto arbitrario $x^{(0)}$ en el que se debe conocer el valor inicial de la función objetivo a minimizar. En cada paso $k \\geq 0$ se avanza de forma iterativa en la dirección opuesta al gradiente, ya que se trabaja con problemas a minimizar. Cabe destacar que esto no supone un límite a la hora de definir la cantidad de problemas que se pueden resolver con esta técnica, ya que todos los problemas a maximizar se pueden transformar en problemas a minimizar. La busqueda de la solución utilizando el descenso por gradiente se puede resumir mediante la siguiente expresión matemática.\n",
    "\n",
    "$$ x^{(k+1)} = x^{(k)} - t_k \\nabla f(x^{(k)})$$\n",
    "\n",
    "Donde $x^{(k+1)}$ corresponde al nuevo punto, $x^{(k+1)}$, $x^{(k)}$ representa el punto actual en el que se encuentra el algoritmo, $t_k$ hace referencia al tamaño del paso (también se utiliza $\\alpha$ para representar la tasa de aprendizaje) y $\\nabla f(x^{(k)})$ corresponde al gradiente en el punto actual. \n",
    "\n",
    "Tal y como se aprecia en la expresión anterior, para encontrar el nuevo punto el algoritmo se avanza en el sentido opuesto al gradiente, esto se indica mediante el signo negativo.\n",
    "\n",
    "A continuación, se adjunta el pseudo-código del descenso por gradiente.\n",
    "\n",
    "<img src=\"imagenes/pseudo_GD.PNG\" width=\"300\"/>\n",
    "<center>Imagen 3. Pseudo-código del descenso por gradiente.</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f81679",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\",text-align:center>\n",
    "\n",
    "<details>\n",
    "<summary><p style=\"text-align:left\"> >>Información tasa de aprendizaje </p></summary>\n",
    "\n",
    "La tasa de aprendizaje también conocida como tamaño del paso, suele tomar un valor pequeño. Existen algunas variantes del algoritmo en las que se evalúa y se actualiza en función del comportamiento de la función de coste. Mediante estas estrategias se busca explorar el espacio de soluciones en las primeras iteraciones y explotar las buenas soluciones conforme avanzan las iteraciones. (https://www.ibm.com/mx-es/topics/gradient-descent)\n",
    "    \n",
    "Una tasa de aprendizaje alta conlleva pasos más grandes, por lo que puede que el algoritmo encuentre la solución antes pero se corre el riesgo de sobrepasar el minimo y que el algoritmo no converja a una solución. El descenso del gradiente con una tasa baja, sin embargo, avanza muy despacio y necesita muchas iteraciones para encontrar una buena solución, resultando así un proceso muy costoso.  \n",
    "\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b5b8b",
   "metadata": {},
   "source": [
    "#### 6.2.1.3. Problemas del descenso por gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7eedcd",
   "metadata": {},
   "source": [
    "El algoritmo de descenso por gradiente se basa en que la **función de coste es convexa**, cuando esta condición se cumple el algoritmo de descenso por gradiente encuentra con facilidad el mínimo global. Cuando se tratan problemas no convexos sin embargo, este algoritmo puede encontrarse con dificultades para llegar hasta el minimo global y quedarse atrapado en minimos locales.\n",
    "\n",
    "Es importante recordar que cuando la pendiente de la función de coste (el gradiente de la función) es cercana a cero el modelo deja de aprende, dejando al algoritmo atrapado en dichos puntos. Cabe destacar que esta situación se puede producir también en puntos silla (también llamados puntos de inflexión) y minimos locales, por lo que en estos casos hacer uso del descenso por gradiente no asegura el obtener la solución óptima al problema. \n",
    "    \n",
    "    \n",
    "<img src=\"imagenes/punto_inflexion.png\" width=\"350\"/>\n",
    "<center>Imagen 4. Ejemplo de máximo, mínimo y punto silla de una función.</center>\n",
    "    \n",
    "Se detectan otras dos dificultades al utilizar el descenso por gradiente para ajustar los parémetros de las redes neuronales.\n",
    "\n",
    "- **Desvanecimiento del gradiente** (gradientes fuga), esto ocurre cuando el gradiente es demasiado pequeño en la retropropagación en las redes neuronales. El gradiente se reduce lo que provoca que las capas intermedias de la red aprendan muy lentamente, cuando esto sucede los parámetros se actualizan hasta que toman el valor nulo. Cuando esto ocurre el algoritmo que se esta entrenando deja de aprender.\n",
    "\n",
    "- El problema de **gradientes explosivos** es justamente el opuesto al anterior, es decir, cuando el gradiente es demasiado grande. En estos casos se crea un modelo inestable, los pesos de la red neuronal crecen demasiado hasta que pasan a tomar el valor NaN.\n",
    "\n",
    "https://www.ibm.com/mx-es/topics/gradient-descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac0963",
   "metadata": {},
   "source": [
    "#### 6.2.1.4 Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d09457",
   "metadata": {},
   "source": [
    "Para visualizar el funcionamiento de este algoritmo de optimización, a continuación se implementa el ejemplo mostrado en el notebook de VQC modificando unicamente el optimizador utilizado. \n",
    "\n",
    "El problema a resolver es un ejemplo básico con el que se demuestra el uso de un clasificador cuántico variacional para reproducir la función de paridad\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&f: \\{0,1\\}^n \\rightarrow \\{0, 1\\}\\\\\n",
    "&f(x) = x_1 \\oplus x_2 \\oplus \\dots \\oplus x_n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "tal que $f(x) = 1$ si y solo si el número de unos en $x$ es impar y $f(x)=0$ en el otro caso.\n",
    "\n",
    "Se puede consultar el ejemplo de aplicación en el siguiente [enlace](3_VQC.ipynb#Ejemplo) para obtener más detalles a cerca del problema a resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87d150",
   "metadata": {},
   "source": [
    "Para poder trabajar con el ejemplo planteado, primero se instala la librería PennyLane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038bf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pennylane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b1c4b7",
   "metadata": {},
   "source": [
    "Una vez instalada, se carga la librería y las herramientas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a2f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8436f4",
   "metadata": {},
   "source": [
    "El problema XOR de 4 bits se puede codificar mediante el *basis embedding* usando cuatro qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e3b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "def statepreparation(x:list):\n",
    "    # expects a list of 0 and 1\n",
    "    # a way to encode data inputs x into the circuit\n",
    "    qml.BasisState(x, wires=list(range(n_qubits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda98674",
   "metadata": {},
   "source": [
    "Se define una capa del circuito mediante rotaciones arbitrarias [Rot](https://docs.pennylane.ai/en/stable/code/api/pennylane.Rot.html#pennylane.Rot) y puertas [CNOT](https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61551e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.01764052  0.00400157  0.00978738]\n",
      "  [ 0.02240893  0.01867558 -0.00977278]\n",
      "  [ 0.00950088 -0.00151357 -0.00103219]\n",
      "  [ 0.00410599  0.00144044  0.01454274]]\n",
      "\n",
      " [[ 0.00761038  0.00121675  0.00443863]\n",
      "  [ 0.00333674  0.01494079 -0.00205158]\n",
      "  [ 0.00313068 -0.00854096 -0.0255299 ]\n",
      "  [ 0.00653619  0.00864436 -0.00742165]]] 0.0\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "def layer(weight):\n",
    "    # arbitrary rotation on every qubit\n",
    "    qml.Rot(weight[0, 0], weight[0, 1], weight[0, 2], wires=0)\n",
    "    qml.Rot(weight[1, 0], weight[1, 1], weight[1, 2], wires=1)\n",
    "    qml.Rot(weight[2, 0], weight[2, 1], weight[2, 2], wires=2)\n",
    "    qml.Rot(weight[3, 0], weight[3, 1], weight[3, 2], wires=3)\n",
    "    #CNOTs to entangle each qubit with the neighbor next to it\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[3, 0])\n",
    "    \n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    statepreparation(x)\n",
    "    for weight in weights:\n",
    "        layer(weight)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier(weights, bias, x):\n",
    "    # classical bias parameter\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "def sqloss_acc(labels, predictions):\n",
    "    sqloss = 0\n",
    "    acc = 0\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        sqloss = sqloss + (label - prediction)**2\n",
    "        if abs(label-prediction) < 1e-5:\n",
    "            acc += 1\n",
    "    sqloss = sqloss / len(labels)\n",
    "    acc = acc / len(labels)\n",
    "    return sqloss, acc\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return sqloss_acc(Y, predictions)[0]\n",
    "\n",
    "def parity_data():\n",
    "    data = np.array([\n",
    "        [0,0,0,0,0],\n",
    "        [0,0,0,1,1],\n",
    "        [0,0,1,0,1],\n",
    "        [0,0,1,1,0],\n",
    "        [0,1,0,0,1],\n",
    "        [0,1,0,1,0],\n",
    "        [0,1,1,0,0],\n",
    "        [0,1,1,1,1],\n",
    "        [1,0,0,0,1],\n",
    "        [1,0,0,1,0],\n",
    "        [1,0,1,0,0],\n",
    "        [1,0,1,1,1],\n",
    "        [1,1,0,0,0],\n",
    "        [1,1,0,1,1],\n",
    "        [1,1,1,0,1],\n",
    "        [1,1,1,1,0],\n",
    "    ], requires_grad=False)\n",
    "    X = np.array(data[:, :-1], requires_grad=False)\n",
    "    Y = np.array(data[:, -1], requires_grad=False)\n",
    "    Y = Y * 2 - np.ones(len(Y))  # shift label from {0, 1} to {-1, 1}\n",
    "    return X, Y\n",
    "\n",
    "X, Y = parity_data()\n",
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588a7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5\n",
    "\n",
    "# batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "# X_batch = X[batch_index]\n",
    "# Y_batch = Y[batch_index]\n",
    "\n",
    "# print(X_batch)\n",
    "# print(Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf782eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     2 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     3 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     4 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     5 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     6 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     7 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     8 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     9 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    10 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    11 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    12 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    13 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    14 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    15 | Cost: 1.5000000 | Accuracy: 0.6250000 \n",
      "Iter:    16 | Cost: 1.5000000 | Accuracy: 0.6250000 \n",
      "Iter:    17 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    18 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    19 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    20 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    21 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    22 | Cost: 1.0000000 | Accuracy: 0.7500000 \n",
      "Iter:    23 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    24 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    25 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    26 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    27 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    28 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    29 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    30 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    31 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    32 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    33 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    34 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    35 | Cost: 0.0000000 | Accuracy: 1.0000000 \n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    statepreparation(x)\n",
    "    for weight in weights:\n",
    "        layer(weight)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "n_iter = 35\n",
    "opt = GradientDescentOptimizer(0.25)\n",
    "batch_size = 5\n",
    "np.random.seed(123)\n",
    "\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(n_iter):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "#     print(batch_index)\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    # the optimizer needs a callable cost function\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    cost_, acc = sqloss_acc(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost_, acc\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6e0512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭BasisState(M0)──Rot(0.02,1.31,0.00)──╭●───────╭X──Rot(0.01,0.00,0.00)───╭●───────╭X─┤  <Z>\n",
      "1: ─├BasisState(M0)──Rot(0.02,1.50,-0.00)─╰X─╭●────│───Rot(0.01,0.17,-0.00)──╰X─╭●────│──┤     \n",
      "2: ─├BasisState(M0)──Rot(0.01,0.06,-0.00)────╰X─╭●─│───Rot(0.00,-0.00,-0.03)────╰X─╭●─│──┤     \n",
      "3: ─╰BasisState(M0)──Rot(0.00,1.33,0.01)────────╰X─╰●──Rot(0.00,1.34,-0.01)────────╰X─╰●─┤     \n"
     ]
    }
   ],
   "source": [
    "drawer = qml.draw(circuit)\n",
    "print(drawer(weights, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba49ae",
   "metadata": {},
   "source": [
    "### 6.2.2. Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e1fb3",
   "metadata": {},
   "source": [
    "Como se ha comentado en el apartado 2.1.3 el algoritmo de descenso por gradiente puede encontrarse con ciertas dificultades que empeoren considerablemente su funcionamiento. Esto principalmente se debe a que el resultado obtenido tiene una gran dependencia en la tasa de aprendizaje y en el gradiente del paso actual, por lo que al no tener en cuenta la trayectoria de soluciones exploradas se puede quedar atrapado en puntos que aparentan ser una buena solución (por ejemplo mínimos locales y puntos silla). Para intentar solventar este tipo de dificultades se implementa el concepto de Momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717a060",
   "metadata": {},
   "source": [
    "#### 6.2.2.1. Idea intuitiva del algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e2b0a6",
   "metadata": {},
   "source": [
    "La implementación del momentum pretende actuar como inercia, es decir, el algoritmo se podría asemejar con una pelota que rueda ladera abajo de manera que cuando encuentre un mínimo local sea capaz de superarlo por la incercia. (https://www.codingninjas.com/codestudio/library/gradient-descent-with-momentum)\n",
    "\n",
    "Por lo tanto, el método que incluye el momentum se trata de una extensión del algoritmo de descenso por gradiente y se le conoce como **descenso por gradiente con momentum**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a29511",
   "metadata": {},
   "source": [
    "#### 6.2.2.2. Algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196146f",
   "metadata": {},
   "source": [
    "Como se ha comentado anteriormente este algoritmo es una extensión de la técnica anterior, por lo que la estrategía a seguir es muy similar. La pregunta que nos surge es como implementar el momentum en la técnia explicada en el apartado 2.1.\n",
    "\n",
    "Para integrar la inercia se puede hacer uso del concepto estadístico de media móvil sobre los gradientes pasados. En las regiones donde la pendiente es alta, las actualizaciones serán significativas, de manera que en cierto modo, se gana impulso al tomar una media móvil sobre estos gradientes. \n",
    "\n",
    "Utilizando esta técnica se consigue introducir la inercia que se comentaba. Sin embargo, utilizando este concepto estadístico todos los gradientes tienen la misma ponderación, en otras palabras, se les otorga la misma importancia a todos los gradientes independientemente de la lejanía del momento actual. Es por esto que se utiliza un promedio ponderado, de manera que los gradientes más recientes tengan mayor importancia.\n",
    "\n",
    "El algoritmo no sufre variaciones drasticas, unicamente se debe tener en cuenta la variación a la hora de calcular el gradiente. En el descenso por gradiente con momentum el valor del siguiente punto se calcula mediante la siguiente expresión:\n",
    "\n",
    "$$ x^{(k+1)} = x^{(k)} - a^{(k+1)}$$\n",
    "\n",
    "el término $a^{(k+1)}$ se actualiza mediante la siguiente expresión $ a^{(k+1)} = \\beta a^{(k)} + t_k \\nabla f(x^{(k)})$ donde $t_k$ corresponde al tamaño de paso y $\\beta$ corresponde al momentum, este parámetro debe cumplir que $ \\beta \\in [0,1]$.\n",
    "https://docs.pennylane.ai/en/stable/code/api/pennylane.MomentumOptimizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a33d8",
   "metadata": {},
   "source": [
    "#### 6.2.2.3. Como seleccionar $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3168236",
   "metadata": {},
   "source": [
    "Al introducir el momentum se debe ajustar un nuevo parámetro, este corresponde al peso que le otorgamos a los gradientes anteriores y se denomina $\\beta$. Si el valor de $\\beta$ es pequeño el gradiante se reduce rápidamente pudiendo crear problemas de gradiente desvaneciente. Si se le asigna un valor demasiado grande, sin embargo, este no se reducirán tan rápido por lo que influirán más gradientes en la actualización, este segundo caso es el ideal. Cabe destacar que el valor más común para este parámetos es $0.9$.\n",
    "\n",
    "https://www.coursera.org/lecture/deep-neural-network/gradient-descent-with-momentum-y0m1f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb37dbfb",
   "metadata": {},
   "source": [
    "#### 6.2.2.4. Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4733ef",
   "metadata": {},
   "source": [
    "Para apreciar las diferencias entre los métodos, desarrollaremos el mismo ejemplo con este segundo optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b1181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     2 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     3 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     4 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     5 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     6 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     7 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     8 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     9 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    10 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    11 | Cost: 2.5000000 | Accuracy: 0.3750000 \n",
      "Iter:    12 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    13 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    14 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    15 | Cost: 1.5000000 | Accuracy: 0.6250000 \n",
      "Iter:    16 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    17 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    18 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    19 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    20 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    21 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    22 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    23 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    24 | Cost: 1.0000000 | Accuracy: 0.7500000 \n",
      "Iter:    25 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    26 | Cost: 1.0000000 | Accuracy: 0.7500000 \n",
      "Iter:    27 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    28 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    29 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    30 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    31 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    32 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    33 | Cost: 1.0000000 | Accuracy: 0.7500000 \n",
      "Iter:    34 | Cost: 1.0000000 | Accuracy: 0.7500000 \n",
      "Iter:    35 | Cost: 1.0000000 | Accuracy: 0.7500000 \n"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    statepreparation(x)\n",
    "    for weight in weights:\n",
    "        layer(weight)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "\n",
    "from pennylane.optimize import MomentumOptimizer\n",
    "\n",
    "n_iter = 35\n",
    "# opt = MomentumOptimizer(0.5)\n",
    "opt = MomentumOptimizer(stepsize=0.25, momentum=0.9)\n",
    "batch_size = 5\n",
    "np.random.seed(123)\n",
    "\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(n_iter):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "#     print(batch_index)\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    # the optimizer needs a callable cost function\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    cost_, acc = sqloss_acc(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost_, acc\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f7a8e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭BasisState(M0)──Rot(0.02,-1.31,0.02)─╭●───────╭X──Rot(0.01,0.00,0.00)───╭●───────╭X─┤  <Z>\n",
      "1: ─├BasisState(M0)──Rot(0.02,4.44,-0.01)─╰X─╭●────│───Rot(-0.14,2.71,-0.00)─╰X─╭●────│──┤     \n",
      "2: ─├BasisState(M0)──Rot(0.01,2.66,0.03)─────╰X─╭●─│───Rot(0.10,-0.45,-0.03)────╰X─╭●─│──┤     \n",
      "3: ─╰BasisState(M0)──Rot(0.00,1.25,0.01)────────╰X─╰●──Rot(0.01,1.36,-0.01)────────╰X─╰●─┤     \n"
     ]
    }
   ],
   "source": [
    "drawer = qml.draw(circuit)\n",
    "print(drawer(weights, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593ee1c",
   "metadata": {},
   "source": [
    "### 6.2.3. Nesterov Momentum Optimizer (descenso por gradiente con Nertorv Momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc317619",
   "metadata": {},
   "source": [
    "Al igual que los dos métodos anteriores, este algoritmo de optimización también se basa en el gradiente. No obstante, cuenta con una mayor tasa de convergencia en ciertas situaciones. http://www.cs.toronto.edu/~fritz/absps/momentum.pdf\n",
    "\n",
    "El optimizador Nesterov Momentum es similar al descenso por gradiente con momentum, pero este desplaza el punto actual mediante el término de momentum al calcular el gradiente. De manera que la única modificación respecto a la técnica anterior es la expresión para actualizar $a^{(k+1)}$ que se sustituye por $a^{(k+1)} = \\beta a^{(k)} + t_k \\nabla f(x^{(k)} - \\beta a^{(k)})$.\n",
    "\n",
    "https://docs.pennylane.ai/en/stable/code/api/pennylane.NesterovMomentumOptimizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98784c",
   "metadata": {},
   "source": [
    "#### 6.2.3.1. Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "151d7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     2 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     3 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     4 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     5 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     6 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     7 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     8 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     9 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    10 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    11 | Cost: 1.0000000 | Accuracy: 0.7500000 \n",
      "Iter:    12 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    13 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    14 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    15 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    16 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    17 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    18 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    19 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    20 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    21 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    22 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    23 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:    24 | Cost: 0.5000000 | Accuracy: 0.8750000 \n",
      "Iter:    25 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    26 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    27 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    28 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    29 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    30 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    31 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    32 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    33 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    34 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    35 | Cost: 0.0000000 | Accuracy: 1.0000000 \n"
     ]
    }
   ],
   "source": [
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    statepreparation(x)\n",
    "    for weight in weights:\n",
    "        layer(weight)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "n_iter = 35\n",
    "# opt = NesterovMomentumOptimizer(0.5)\n",
    "opt = NesterovMomentumOptimizer(stepsize=0.25, momentum=0.9)\n",
    "batch_size = 5\n",
    "np.random.seed(123)\n",
    "\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(n_iter):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "#     print(batch_index)\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    # the optimizer needs a callable cost function\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    cost_, acc = sqloss_acc(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost_, acc\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7fbb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭BasisState(M0)──Rot(0.02,1.59,-0.01)─╭●───────╭X──Rot(0.01,0.00,0.00)───╭●───────╭X─┤  <Z>\n",
      "1: ─├BasisState(M0)──Rot(0.02,4.83,0.02)──╰X─╭●────│───Rot(0.12,3.21,-0.00)──╰X─╭●────│──┤     \n",
      "2: ─├BasisState(M0)──Rot(0.01,-0.21,0.06)────╰X─╭●─│───Rot(0.00,-0.34,-0.03)────╰X─╭●─│──┤     \n",
      "3: ─╰BasisState(M0)──Rot(0.00,1.62,-0.03)───────╰X─╰●──Rot(-0.03,1.35,-0.01)───────╰X─╰●─┤     \n"
     ]
    }
   ],
   "source": [
    "drawer = qml.draw(circuit)\n",
    "print(drawer(weights, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270455c",
   "metadata": {},
   "source": [
    "## OTROS OPTIMIZADORES QUE NO SE PUEDEN UTILIZAR EN CLASIFICACIÓN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f197ac",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">NO SE PUEDE UTILIZAR PARA CLASIFICACIÓN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031ccff",
   "metadata": {},
   "source": [
    "### 6.2.4. RotosolveOptimizer (free gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e921db0",
   "metadata": {},
   "source": [
    "Rotosolve es un algoritmo de optimización que trata de obtener los parámetros de rotación de las puertas cuánticas que minimicen el valor de una función. Se trata de una estrategia gradient free, es decir, este algoritmo no hace uso del gradiente para llegar al mínimo.\n",
    "\n",
    "Este método es un algoritmo de optimización coordinada aplicado a los ángulos de rotación, $\\theta = \\theta_1, ..., \\theta_D$. Encuentra el ángulo óptimo para una puerta mientras fija los demás a sus valores actuales, el algoritmo recorre secuencialmente y de forma cíclica todas las puertas para actualizar los parámetros. Para la puerta $U_d$ el ángulo óptimo se calcula mediante la siguiente expresión.\n",
    "\n",
    "$$\n",
    "\\theta_d^* = \\text {argmin}_{\\theta_d} \\langle H \\rangle_{\\theta_d} = -\\frac{\\pi}{2} - \\text{argtan2} \\left( 2\\langle H \\rangle_{\\theta_d=0} - \\langle H \\rangle_{\\theta_d=\\pi/2} - \\langle H \\rangle_{\\theta_d=-\\pi/2}, \\langle H \\rangle_{\\theta_d=\\pi/2} - \\langle H \\rangle_{\\theta_d=-\\pi/2} \\right)\n",
    "$$\n",
    "\n",
    "El ángulo óptimo se puede encontrar para todos los $d=1,...,D$ al completar el ciclo. Una vez se han actualizado todo los ángulos comienza un nuevo ciclo, siempre y cuando no se cumpla el criterio de parada fijado. En este algoritmo se pueden utilizar varios criterios de parada como fijar un número máximo de ciclos a realizar o que la función objetivo no se haya reducido en un número de ciclos fijados inicialmente, por ejemplo.\n",
    "\n",
    "<img src=\"imagenes/Rotosolve_alg.PNG\" width=\"700\"/>\n",
    "<center>Imagen 5. Pseudo-código del algoritmo de optimización RotoSolve.</center>\n",
    "\n",
    "\n",
    "Como se ha comentado anteriormente, este método no optimiza el circuito. La estructura del circuito normalmente se basa en el conocimiento que el progrador conoce a cerca del problema y de las restricciones que tiene el hardware a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c83c3",
   "metadata": {},
   "source": [
    "#### 6.2.4.1. Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae593969",
   "metadata": {},
   "source": [
    "### 6.2.5. RotoselectOptimizer (free gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b67fc",
   "metadata": {},
   "source": [
    "El algoritmo Rotoselect es un método de optimización similar al anterior, ya que se trata de un optimizador que no hace uso del gradiente para encontrar la mejor solución. Este método sin embargo, no solo optimiza los parámetros de las puertas cuánticas sino que también selecciona las mejores puertas de rotación a aplicar con el objetivo de minimizar la función objetivo.\n",
    "\n",
    "Esta estrategia actualiza los parámetros $\\theta = \\theta_1, ..., \\theta_D$ y las puertas de rotación $R = R_1,...,R_D$ según la expresión para el valor óptimo del parámetro $d$-ésimo $\\theta^*_d$ fijando los parámetros restantes, la expresión utilizada para actualizar los ángulos de rotación es la misma que en el algoritmo Rotosolver:\n",
    "\n",
    "$$\n",
    "\\theta_d^* = \\text {argmin}_{\\theta_d} \\langle H \\rangle_{\\theta_d} = -\\frac{\\pi}{2} - \\text{argtan2} \\left( 2\\langle H \\rangle_{\\theta_d=0} - \\langle H \\rangle_{\\theta_d=\\pi/2} - \\langle H \\rangle_{\\theta_d=-\\pi/2}, \\langle H \\rangle_{\\theta_d=\\pi/2} - \\langle H \\rangle_{\\theta_d=-\\pi/2} \\right)\n",
    "$$\n",
    "\n",
    "donde $\\langle H \\rangle_{\\theta_d}$ es el valor esperado de la función objetivo optimizada sobre el parametro $\\theta_d$. Recalcar que las puertas cuánticas para n-qubits se generan mediante matrices hermiticas y unitarias mediante productos tensoriales de matrices de Pauli $H_d \\in \\{I,X,Y,Z\\}^{\\otimes n}$. La optimización de la estructura consiste en encontrar el set óptimo de generadores, sin duda un problema combinatorio.\n",
    "\n",
    "La técnica trata de aproximar los ángulos de rotación mediante la expresión anterior para encontrar el mínimo $ \\theta^*_d(P) = \\text{argmin}_{\\theta_d} \\langle M \\rangle_{\\theta_d, P}$ para todos los generadores $P \\in \\{I,X,Y,Z\\}^{\\otimes n}$. En este caso el segundo subíndice indica que P es el generador utilizado en la d-ésima puerta.\n",
    "\n",
    "Entonces, $H_d$ se le asigna al generador que menor energía produce y $\\theta_d$ al ángulo que minimiza la función. Este proceso se repite para $d=1,...,D$ hasta completar el ciclo y el algoritmo se ejecuta de manera iterativa hasta cumplir con el criterio de parada.\n",
    "\n",
    "De manera visual, la idea que persigue este algoritmo a la hora de optimizar el circuito es la que sigue:\n",
    "\n",
    "<img src=\"imagenes/Rotoselect_circ.PNG\" width=\"400\"/>\n",
    "<center>Imagen 6. Visualización de la optimización las puertas de rotación.</center>\n",
    "\n",
    "Como se aprecia en la imagen anterior, se define el circuito con puertas genéricas y el propio algoritmo es el que selecciona la puerta de Pauli a aplicar, es decir, $P_d \\in \\{X,Y,Z\\}$. Por ejemplo, $U(\\theta, Z) = R_{z}(\\theta)$.\n",
    "https://pennylane.ai/qml/demos/tutorial_rotoselect.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4859dc",
   "metadata": {},
   "source": [
    "#### 6.2.5.1. Implementación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6148664b",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "## Referencias\n",
    "<a id='referencias'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8dd766",
   "metadata": {},
   "source": [
    "This work has been financially supported by the Ministry of Economic Affairs and Digital Transformation of the Spanish Government through the QUANTUM ENIA project call - Quantum Spain project, and by the European Union through the Recovery, Transformation and Resilience Plan - NextGenerationEU within the framework of the Digital Spain 2025 Agenda.\n",
    "\n",
    "\n",
    "<img align=\"left\" src=\"https://quantumspain-project.es/wp-content/uploads/2022/11/LOGOS-GOB_QS.png\" width=\"1000px\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
