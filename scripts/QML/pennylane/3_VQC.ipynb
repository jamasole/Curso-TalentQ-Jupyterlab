{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec3d300",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://quantumspain-project.es/wp-content/uploads/2022/11/Logo_QS_EspanaDigital.png\" width=\"1000px\"/><br><br><br><br>\n",
    "\n",
    "\n",
    "# QML (Quantum Machine Learning)\n",
    "\n",
    "Created: 2022/10/30\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img aling=\"left\" alt=\"Licencia Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />License: <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional</a>.\n",
    "Internal Reviewers:\n",
    "* Alba Cervera ([BSC](https://www.bsc.es/))\n",
    "\n",
    "Authors:\n",
    "* Carmen Calvo ([SCAYLE](https://www.scayle.es/))\n",
    "* Antoni Alou ([PIC](https://www.pic.es/))\n",
    "* Carlos Hernani ([UV](https://www.uv.es/))\n",
    "* Nahia Iriarte ([NASERTIC](https://www.nasertic.es/es))\n",
    "* Carlos Luque ([IAC](https://www.iac.es/))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736be1ca",
   "metadata": {},
   "source": [
    "Consulta la notación que se ha utilizado durante todo el documento en el siguiente [enlace](#notacion)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a429357",
   "metadata": {},
   "source": [
    "# 3. Variational Quantum Classifier (VQC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53912b98",
   "metadata": {},
   "source": [
    "Existen múltiples métodos para clasificar un conjunto de datos utilizando un ordenador cuántico, uno de ellos es el algoritmo conocido como ***Variational Quantum Classifier*** o **VQC**.\n",
    "\n",
    "El VQC es un algoritmo de aprendizaje supervisado que hace uso de un circuito cuántico variacional. El circuito cuántico variacional, también llamado circuito cuántico parametrizado, realiza una función similar a la arquitectura de una red neuronal clásica.\n",
    "\n",
    "Al igual que el aprendizaje automático clásico, el algoritmo VQC tiene una fase de entrenamiento, en la que se proporcionan datos etiquetados, y una fase de validación, en la que se clasifican nuevos datos con el modelo ya entrenado para así evaluar la calidad del modelo [[1]](#referencias). Se trata de un algoritmo de clasificación híbrido ya que combina una componente cuántica y una componente clásica, tal y como se aprecia en la imagen 1, que realiza un bucle de optimización de los parámetros del circuito cuántico. \n",
    "\n",
    "Comienza con la componente cuántica, en esta fase se lleva a cabo el preprocesamiento de los datos, la preparación de los estados cuánticos y se ejecuta el circuito correspondiente al algoritmo. Una vez se completa la primera fase, el algoritmo hace uso de la componente clásica. Esta última, ajusta la función de coste y actualiza los parámetros en función de la salida obtenida en el circuito.\n",
    "\n",
    "<center><img src=https://raw.githubusercontent.com/born-2learn/born-2learn.github.io/master/_posts/images/vqc-part1/qml-workflow.png width=\"400\"></center>\n",
    "\n",
    "<center>Imagen 1. Etapas algoritmo QML [5]</center>\n",
    "\n",
    "Ambas fases se llevan a cabo de forma iterativa, es decir, los valores de los parámetros se actualizan con los obtenidos en la componente clásica y se iniciará de nuevo el proceso con la finalidad de obtener la mejor solución. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b246015",
   "metadata": {},
   "source": [
    "<a id='VariationalQuantumCirc'></a>\n",
    "## 3.1. Variational Quantum Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9277bf4a",
   "metadata": {},
   "source": [
    "Los circuitos cuánticos variacionales o parametrizados son circuitos que dependen de parámetros configurables que se optimizan mediante un coprocesador clásico para la realización de una tarea determinada.\n",
    "\n",
    "El principio de funcionamiento de los circuitos variacionales es muy similar al de las redes neuronales clásicas, por lo que desempeñan un papel importante en el aprendizaje automático en ordenadores cuánticos.\n",
    "\n",
    "En general, todo circuito variacional se divide en tres pasos:\n",
    "\n",
    "1. **Preparación de datos (*State Preparation*)**: Los datos clásicos necesitan ser trasladados a estados cuánticos en un espacio de Hilbert mediante un mapeado de características cuántico (***Quantum Feature Map***). A este paso se le conoce también como ***quantum embedding*** o ***data encoding***. Para conocer más a cerca de estas técnicas puede consultar el siguiente [*enlace*](2_Feature_encoding.ipynb).\n",
    "\n",
    "\n",
    "2. **Circuito parametrizado**: El circuito diseñado para realizar una tarea concreta, por ejemplo clasificación, está caracterizado por un operador unitario parametrizado $U(x, \\theta)$. Siendo $x$ la entrada del circuito (los datos anteriormente codificados) y $\\theta$ los parámetros variacionales. \n",
    "\n",
    "\n",
    "3. **Medida/Optimización**: En esta etapa se produce la medida de un observable a la salida del circuito. El circuito del paso anterior se ejecuta conjuntamente con un coprocesador clásico que realiza el cálculo de la función de coste a partir del valor esperado del observable medido y la actualización de los parámetros variacionales a partir de la salida del circuito [[2]](#referencias).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b17f9",
   "metadata": {},
   "source": [
    "<a id='Ejemplo'></a>\n",
    "## 3.2. Ejemplo de aplicación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314ee1b",
   "metadata": {},
   "source": [
    "A continuación, se recoge un ejemplo básico con el que se demuestra el uso de un clasificador cuántico variacional para reproducir la función de paridad\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&f: \\{0,1\\}^n \\rightarrow \\{0, 1\\}\\\\\n",
    "&f(x) = x_1 \\oplus x_2 \\oplus \\dots \\oplus x_n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "tal que $f(x) = 1$ si y solo si el número de unos en $x$ es impar y $f(x)=0$ en el otro caso.\n",
    "\n",
    "Este ejemplo de optimización demuestra cómo codificar entradas binarias en el estado inicial del circuito variacional [[3]](#referencias). \n",
    "\n",
    "El clasificador está escrito en Python usando la librería PennyLane, un *framework* para programación cuántica similar a los utilizados en la computación clásica, Tensorflow o PyTorch. PennyLane está desarrollado en base a la idea de entrenar circuitos cuánticos utilizando la diferenciación automática. Esto es especialmente importante en aplicaciones como el aprendizaje automático cuántico, la química cuántica y la optimización cuántica [[4]](#referencias).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee6edf",
   "metadata": {},
   "source": [
    "Primero se instala la librería PennyLane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1b07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pennylane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f258b58f",
   "metadata": {},
   "source": [
    "Una vez instalada, se carga la librería y las herramientas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f4d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b5b24",
   "metadata": {},
   "source": [
    "El problema XOR de 4 bits se puede codificar mediante el *basis embedding* usando cuatro qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4283fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "def statepreparation(x:list):\n",
    "    # expects a list of 0 and 1\n",
    "    # a way to encode data inputs x into the circuit\n",
    "    qml.BasisState(x, wires=list(range(n_qubits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7677a236",
   "metadata": {},
   "source": [
    "Se define una capa del circuito mediante rotaciones arbitrarias [Rot](https://docs.pennylane.ai/en/stable/code/api/pennylane.Rot.html#pennylane.Rot) y puertas [CNOT](https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c58f17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "def layer(weight):\n",
    "    # arbitrary rotation on every qubit\n",
    "    qml.Rot(weight[0, 0], weight[0, 1], weight[0, 2], wires=0)\n",
    "    qml.Rot(weight[1, 0], weight[1, 1], weight[1, 2], wires=1)\n",
    "    qml.Rot(weight[2, 0], weight[2, 1], weight[2, 2], wires=2)\n",
    "    qml.Rot(weight[3, 0], weight[3, 1], weight[3, 2], wires=3)\n",
    "    #CNOTs to entangle each qubit with the neighbor next to it\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[3, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a0b73",
   "metadata": {},
   "source": [
    "Se define el circuito variacional como la unión de las tres etapas mencionadas anteriormente : \n",
    "\n",
    "- Preparación del estado.\n",
    "- Circuito.\n",
    "- Medida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f235b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    statepreparation(x)\n",
    "    for weight in weights:\n",
    "        layer(weight)\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30151e",
   "metadata": {},
   "source": [
    "Se define el clasificador (*variational quantum classifier*) como el circuito anterior y un término clásico, *bias*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7220c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    # classical bias parameter\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d5c78",
   "metadata": {},
   "source": [
    "Se definen dos funciones de coste distintas, *square loss* y *accuracy*, a continuación se adjunta la expresión matemática de cada una de ellas. \n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathit{\\text{Square loss}} = \\frac {\\sum_{i=1}^N (y_i - \\tilde{y_i})^2}{N} ~~~~~~~~~~\n",
    "\\mathit{\\text{Accuracy}} = \\frac{\\text{Predicciones correctas}}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e9de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqloss_acc(labels, predictions):\n",
    "    sqloss = 0\n",
    "    acc = 0\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        sqloss = sqloss + (label - prediction)**2\n",
    "        if abs(label-prediction) < 1e-5:\n",
    "            acc += 1\n",
    "    sqloss = sqloss / len(labels)\n",
    "    acc = acc / len(labels)\n",
    "    return sqloss, acc\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return sqloss_acc(Y, predictions)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be663bfe",
   "metadata": {},
   "source": [
    "Se generan los datos y los parámetros iniciales del circuito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "145e532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.01764052  0.00400157  0.00978738]\n",
      "  [ 0.02240893  0.01867558 -0.00977278]\n",
      "  [ 0.00950088 -0.00151357 -0.00103219]\n",
      "  [ 0.00410599  0.00144044  0.01454274]]\n",
      "\n",
      " [[ 0.00761038  0.00121675  0.00443863]\n",
      "  [ 0.00333674  0.01494079 -0.00205158]\n",
      "  [ 0.00313068 -0.00854096 -0.0255299 ]\n",
      "  [ 0.00653619  0.00864436 -0.00742165]]] 0.0\n"
     ]
    }
   ],
   "source": [
    "def parity_data():\n",
    "    data = np.array([\n",
    "        [0,0,0,0,0],\n",
    "        [0,0,0,1,1],\n",
    "        [0,0,1,0,1],\n",
    "        [0,0,1,1,0],\n",
    "        [0,1,0,0,1],\n",
    "        [0,1,0,1,0],\n",
    "        [0,1,1,0,0],\n",
    "        [0,1,1,1,1],\n",
    "        [1,0,0,0,1],\n",
    "        [1,0,0,1,0],\n",
    "        [1,0,1,0,0],\n",
    "        [1,0,1,1,1],\n",
    "        [1,1,0,0,0],\n",
    "        [1,1,0,1,1],\n",
    "        [1,1,1,0,1],\n",
    "        [1,1,1,1,0],\n",
    "    ], requires_grad=False)\n",
    "    X = np.array(data[:, :-1], requires_grad=False)\n",
    "    Y = np.array(data[:, -1], requires_grad=False)\n",
    "    Y = Y * 2 - np.ones(len(Y))  # shift label from {0, 1} to {-1, 1}\n",
    "    return X, Y\n",
    "\n",
    "X, Y = parity_data()\n",
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc49f9",
   "metadata": {},
   "source": [
    "Así como los hiperparámetros del entrenamiento y se ejecuta el clasifcador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe8bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     2 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     3 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     4 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     5 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     6 | Cost: 1.5000000 | Accuracy: 0.6250000 \n",
      "Iter:     7 | Cost: 2.0000000 | Accuracy: 0.5000000 \n",
      "Iter:     8 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:     9 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    10 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    11 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    12 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    13 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    14 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    15 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    16 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    17 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    18 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    19 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    20 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    21 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    22 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    23 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    24 | Cost: 0.0000000 | Accuracy: 1.0000000 \n",
      "Iter:    25 | Cost: 0.0000000 | Accuracy: 1.0000000 \n"
     ]
    }
   ],
   "source": [
    "n_iter = 25\n",
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 5\n",
    "\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(n_iter):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    # the optimizer needs a callable cost function\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    cost_, acc = sqloss_acc(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost_, acc\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123b382",
   "metadata": {},
   "source": [
    "Como se puede observar a partir de la iteración $8$, la métrica *accuracy* es $1.0$ i.e. clasifica perfectamente el problema. A continuación, una visualización del circuito variacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "186e985b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭BasisState(M0)──Rot(0.02,1.41,-0.00)──╭●───────╭X──Rot(0.01,0.00,0.00)───╭●───────╭X─┤  <Z>\n",
      "1: ─├BasisState(M0)──Rot(0.02,1.43,-0.00)──╰X─╭●────│───Rot(-0.32,0.03,-0.00)─╰X─╭●────│──┤     \n",
      "2: ─├BasisState(M0)──Rot(0.01,-0.04,-0.06)────╰X─╭●─│───Rot(0.10,0.06,-0.03)─────╰X─╭●─│──┤     \n",
      "3: ─╰BasisState(M0)──Rot(0.00,1.57,0.01)─────────╰X─╰●──Rot(-0.00,1.57,-0.01)───────╰X─╰●─┤     \n"
     ]
    }
   ],
   "source": [
    "drawer = qml.draw(circuit)\n",
    "print(drawer(weights, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc176e7",
   "metadata": {},
   "source": [
    "<a id='notacion'></a>\n",
    "<div class=\"alert alert-block alert-warning\",text-align:center>\n",
    "<b>ANEXO NOTACIÓN:</b>\n",
    "\n",
    "Para que la comprensión de los notebooks sea mejor se ha unificado la notación utilizada en los mismos. Para diferenciar un vector de un valor único se hará uso de la negrita. De manera que $\\mathbf{x}$ corresponde a un vector y $z$ será una variable de una única componente. \n",
    "\n",
    "    \n",
    "Si se quiere hacer referencia a dos vectores distintos pero que pertenecen al mismo *dataset* se utilizará un subíndice, es decir, $\\mathbf{x_i}$ hará referencia al i-ésimo vector del dataset. Si se quiere referenciar una característica concreta del vector $\\mathbf{x_i}$ se añadirá un nuevo subíndice, de manera que $\\mathbf{x_{i_j}}$ hará referencia a la j-ésima variable del i-ésimo vector.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450328e",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "## Referencias\n",
    "<a id='referencias'></a>\n",
    "[1]. https://born-2learn.github.io/posts/2020/12/variational-quantum-classifier/ <br>\n",
    "[2]. https://pennylane.ai/qml/glossary/variational_circuit.html <br>\n",
    "[3]. https://pennylane.ai/qml/demos/tutorial_variational_classifier.html <br>\n",
    "[4]. https://pennylane.ai/faq.html <br>\n",
    "[5]. https://blog.tensorflow.org/2020/03/announcing-tensorflow-quantum-open.html<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d74f55d",
   "metadata": {},
   "source": [
    "This work has been financially supported by the Ministry of Economic Affairs and Digital Transformation of the Spanish Government through the QUANTUM ENIA project call - Quantum Spain project, and by the European Union through the Recovery, Transformation and Resilience Plan - NextGenerationEU within the framework of the Digital Spain 2025 Agenda.\n",
    "\n",
    "\n",
    "<img align=\"left\" src=\"https://quantumspain-project.es/wp-content/uploads/2022/11/LOGOS-GOB_QS.png\" width=\"1000px\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
